{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf2a437",
   "metadata": {},
   "source": [
    "This playbook is inspired by lessons in [Advanced Retrieval for AI with Chroma](https://learn.deeplearning.ai/courses/advanced-retrieval-for-ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc9a6af",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac0d2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install glob langchain-huggingface langchain-community langchain-chroma --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "533a4cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2961\n",
      "page_content='{\"resourceType\": \"Condition\", \"id\": \"0472ed1c-4efa-4c86-bcf1-5eea6bda2432\", \"clinicalStatus\": {\"coding\": [{\"system\": \"http://terminology.hl7.org/CodeSystem/condition-clinical\", \"code\": \"active\"}]}, \"verificationStatus\": {\"coding\": [{\"system\": \"http://terminology.hl7.org/CodeSystem/condition-ver-status\", \"code\": \"confirmed\"}]}, \"code\": {\"coding\": [{\"system\": \"http://snomed.info/sct\", \"code\": \"429007001\", \"display\": \"History of cardiac arrest (situation)\"}], \"text\": \"History of cardiac arrest (situation)\"}, \"subject\": {\"reference\": \"urn:uuid:5cbc121b-cd71-4428-b8b7-31e53eba8184\"}, \"encounter\": {\"reference\": \"urn:uuid:f78d73fc-9f9b-46d5-93aa-f5db86ba914c\"}, \"onsetDateTime\": \"1965-11-15T06:22:41-05:00\", \"recordedDate\": \"1965-11-15T06:22:41-05:00\"}' metadata={'source': 'C:\\\\Users\\\\Peter\\\\Documents\\\\GitHub\\\\agentic-healthcare-analytics\\\\fhir\\\\Aaron697_Brekke496_2fa15bc7-8866-461a-9000-f739e425860a.json', 'seq_num': 6}\n"
     ]
    }
   ],
   "source": [
    "# Document Loading\n",
    "import glob\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "FHIR_BUNDLE_JQ_SCHEMA = \".entry[]\"\n",
    "FHIR_BUNDLE_CONTENT_KEY = \".resource\"\n",
    "\n",
    "synthea_bundles = glob.glob(\"../fhir/*.json\")\n",
    "\n",
    "loaders = [\n",
    "    JSONLoader(\n",
    "        file_path=xpath,\n",
    "        jq_schema=FHIR_BUNDLE_JQ_SCHEMA,\n",
    "        content_key=FHIR_BUNDLE_CONTENT_KEY,\n",
    "        is_content_key_jq_parsable=True,\n",
    "        text_content=False\n",
    "    )\n",
    "    for xpath in synthea_bundles[:10] # limiting to just the first 10 for now\n",
    "]\n",
    "\n",
    "docs = []\n",
    "for loader in loaders:\n",
    "    docs.extend(loader.load())\n",
    "print(len(docs))\n",
    "print(docs[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b2213a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "embedding = OllamaEmbeddings(model=\"llama3.2:1b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d469a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The system cannot find the file specified.\n",
      "The system cannot find the file specified.\n",
      "The system cannot find the file specified.\n",
      "The system cannot find the file specified.\n",
      "The system cannot find the file specified.\n",
      "The system cannot find the file specified.\n"
     ]
    }
   ],
   "source": [
    "# Vector Store\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "persist_directory = 'docs/chroma'\n",
    "!rmdir /s /q \".\\\\docs\\\\chroma\" # clear out the persist directory\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc44ad99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "# !ollama pull llama3.2:1b\n",
    "from langchain_community.llms import Ollama\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:1b\") # using smaller model due to resource limitations on my old laptop ðŸ™ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046a0dc4",
   "metadata": {},
   "source": [
    "## Visualize Embeddings Space\n",
    "Use UMAP projection to visualize the high-dimensional embedding space in 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30281e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install umap tqdm matplotlib --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d371e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "chroma_embeddings = vectordb._collection.get(include=['embeddings'])['embeddings']\n",
    "umap_transform = umap.UMAP(random_state=0, transform_seed=0).fit(chroma_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8444a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_embeddings(embeddings, umap_transform):\n",
    "    umap_embeddings = np.empty((len(embeddings),2))\n",
    "    for i, embedding in enumerate(tqdm(embeddings)): \n",
    "        umap_embeddings[i] = umap_transform.transform([embedding])\n",
    "    return umap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d7a81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected_dataset_embeddings = project_embeddings(chroma_embeddings, umap_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a05d8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(projected_dataset_embeddings[:, 0], projected_dataset_embeddings[:, 1], s=10)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('Projected Embeddings')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af3f09f",
   "metadata": {},
   "source": [
    "## Try Query Expansion\n",
    "\n",
    "Ask LLM to come up with additional questions along the lines of the provided user question and apply those to the VectorDB in addition to the provided user question."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4da6ff",
   "metadata": {},
   "source": [
    "## Try Cross-encoder Re-ranking\n",
    "\n",
    "Cross-encoders are a different method for encoding queries that are related, rather than treating them as independent.... I think ðŸ¤”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a3dbb6",
   "metadata": {},
   "source": [
    "## Try Embedding Adaptors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73be229c",
   "metadata": {},
   "source": [
    "## Try Other Techniques"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
